{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import langgraph\n",
    "from typing import Dict, TypedDict, Annotated, Optional\n",
    "from langchain.document_loaders import PyPDFLoader, UnstructuredWordDocumentLoader\n",
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_google_genai.llms import GoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langgraph.graph import StateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = GoogleGenerativeAI( model = \"gemini-2.0-flash\" )\n",
    "embeddings_model = OllamaEmbeddings( model = \"nomic-embed-text:latest\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResumeState(TypedDict):\n",
    "    folder_path: Annotated[str, \"static\"]  \n",
    "    job_description: Annotated[str, \"static\"]  \n",
    "    resumes: Optional[Dict[str, str]]  \n",
    "    ranked_candidates: Optional[list]  \n",
    "    summaries: Optional[Dict[str, str]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_resumes(state: ResumeState) -> Dict:   \n",
    "    folder_path = state[\"folder_path\"]\n",
    "    resumes = {}\n",
    "\n",
    "    for file in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        if file.endswith(\".pdf\"):\n",
    "            loader = PyPDFLoader(file_path)\n",
    "        elif file.endswith(\".docx\"):\n",
    "            loader = UnstructuredWordDocumentLoader(file_path)\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        docs = loader.load()\n",
    "        text = \"\\n\".join([doc.page_content for doc in docs])\n",
    "        resumes[file] = text\n",
    "\n",
    "    return {\"resumes\": resumes} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_candidates(state: ResumeState) -> Dict:\n",
    "    job_description = state[\"job_description\"]\n",
    "    resumes = state[\"resumes\"]\n",
    "\n",
    "    job_embedding = embeddings_model.embed_query(job_description)\n",
    "    vector_store = FAISS.from_texts(list(resumes.values()), embeddings_model)\n",
    "\n",
    "    ranked_candidates = []\n",
    "    for file, text in resumes.items():\n",
    "        score = vector_store.similarity_search_with_score(job_embedding, k=1)\n",
    "        ranked_candidates.append({\"file\": file, \"score\": score[0][1]})\n",
    "\n",
    "    ranked_candidates.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "    return {\"ranked_candidates\": ranked_candidates}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_candidates(state: ResumeState) -> Dict:\n",
    "    resumes = state[\"resumes\"]\n",
    "    summaries = {}\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"resume\"],\n",
    "        template=\"Summarize the candidate's key strengths from the following resume:\\n{resume}\"\n",
    "    )\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    for file, text in resumes.items():\n",
    "        summaries[file] = chain.run(text)\n",
    "\n",
    "    return {\"summaries\": summaries}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(ResumeState)\n",
    "\n",
    "\n",
    "graph.add_node(\"extract_resumes\", extract_resumes)\n",
    "graph.add_node(\"rank_candidates\", rank_candidates)\n",
    "graph.add_node(\"summarize_candidates\", summarize_candidates)\n",
    "\n",
    "graph.set_entry_point(\"extract_resumes\")\n",
    "graph.add_edge(\"extract_resumes\", \"rank_candidates\")\n",
    "graph.add_edge(\"extract_resumes\", \"summarize_candidates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_agent = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = {\n",
    "    \"folder_path\": \"./ENGINEERING\",\n",
    "    \"job_description\": \"Looking for an autocad professional and who is also well versed with Mocrosoft excel.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = resume_agent.invoke(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìå Ranked Candidates:\")\n",
    "for candidate in output[\"ranked_candidates\"]:\n",
    "    print(f\"‚úÖ {candidate['file']} | Score: {candidate['score']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìú Candidate Summaries:\")\n",
    "for file, summary in output[\"summaries\"].items():\n",
    "    print(f\"üìù {file}: {summary}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
