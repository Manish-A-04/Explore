{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.tools import ArxivQueryRun , WikipediaQueryRun , Tool\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "from langchain_community.utilities import ArxivAPIWrapper,  WikipediaAPIWrapper \n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"qrcode_diffusion.pdf\"\n",
    "pdf_loader = PyPDFLoader(pdf_path)\n",
    "pdf = pdf_loader.load()\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "chunker = SemanticChunker(embeddings=embedding_model , breakpoint_threshold_type=\"percentile\" , min_chunk_size=100)\n",
    "doc_splits = chunker.split_documents(pdf)\n",
    "\n",
    "len(doc_splits)\n",
    "\n",
    "db = Chroma.from_documents(doc_splits , embedding_model)\n",
    "retriever = db.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_tool = Tool(\n",
    "    name=\"Wikipedia Search Tool\",\n",
    "    func=WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(top_k_results=5)).run,\n",
    "    description=\"A tool for using wikipedia to get personalised results\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_tool = Tool(\n",
    "    name=\"ARXIV search Tool\",\n",
    "    func = ArxivQueryRun(api_wrapper=ArxivAPIWrapper(top_k_results=5)).run,\n",
    "    description=\"A tool for using arxiv to search through research papers\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_tool = Tool(\n",
    "    name= \"QR CODE DIFFUSION RESEARCH PAPER TOOL\",\n",
    "    func = retriever.get_relevant_documents,\n",
    "    description=\"A tool for using the knowledgebase of the pdf locally\" \n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "tavily_tool = TavilySearchResults(max_results=5 , search_depth=\"advanced\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai.llms import GoogleGenerativeAI\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "llm = GoogleGenerativeAI(model=\"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I help you today?\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [ arxiv_tool , wiki_tool,  pdf_tool , tavily_tool ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_8348\\600513049.py:3: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_8348\\381962146.py:1: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  res = agent.run(\"Find ways to embed images in qr code\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find information about embedding images in QR codes. I should start by searching for research papers on the topic to get a technical understanding.\n",
      "Action: QR CODE DIFFUSION RESEARCH PAPER TOOL\n",
      "Action Input: \"embedding images in QR codes\"\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m[Document(metadata={'page': 8, 'source': 'qrcode_diffusion.pdf'}, page_content='5\\n[37] Open Source. Zxing: zebra crossing, 2013. 4\\n[38] Hao Su, Jianwei Niu, Xuefeng Liu, Qingfeng Li, Ji Wan,\\nand Mingliang Xu. Q-art code: Generating scanning-robust\\nart-style qr codes by deformable convolution. In ACMMM ,\\n2021. 3\\n[39] Hao Su, Jianwei Niu, Xuefeng Liu, Qingfeng Li, Ji Wan,\\nMingliang Xu, and Tao Ren. Artcoder: an end-to-end\\nmethod for generating scanning-robust stylized qr codes. In\\nCVPR , 2021. 2, 3\\n9'), Document(metadata={'page': 8, 'source': 'qrcode_diffusion.pdf'}, page_content='5\\n[37] Open Source. Zxing: zebra crossing, 2013. 4\\n[38] Hao Su, Jianwei Niu, Xuefeng Liu, Qingfeng Li, Ji Wan,\\nand Mingliang Xu. Q-art code: Generating scanning-robust\\nart-style qr codes by deformable convolution. In ACMMM ,\\n2021. 3\\n[39] Hao Su, Jianwei Niu, Xuefeng Liu, Qingfeng Li, Ji Wan,\\nMingliang Xu, and Tao Ren. Artcoder: an end-to-end\\nmethod for generating scanning-robust stylized qr codes. In\\nCVPR , 2021. 2, 3\\n9'), Document(metadata={'page': 2, 'source': 'qrcode_diffusion.pdf'}, page_content='[46], Qin et al. [27], and Zavadski et al. [45] proposed\\nadaptation strategies that allow users to fine-tune only the\\nextra output layer instead of the entire model. These advancements have significantly impacted fields\\nincluding image editing [4, 6, 10, 11, 22, 23, 25, 43], text-\\nto-image synthesis [29–31], and commercial product de-\\nvelopement, exemplified by DALL-E2 [26] and Midjour-\\nney [14]. 2.2. Aesthetic QR Codes\\n2.2.1 Non-generative-based Models\\nPrevious works on aesthetic QR codes have focused\\non three main techniques: module deformation, module\\nreshuffling, and style transfers. Module-deformation meth-\\nods, such as Halftone QR codes [3], integrate reference\\nimages by deforming and scaling code modules while\\nmaintaining scanning robustness. Module-reshuffling, in-\\ntroduced by Qart [5], rearranges code modules using\\nGaussian-Jordan elimination to align pixel distributions\\nwith reference images to ensure decoding accuracy. Im-\\nage processing techniques have also been developed to en-\\nhance visual quality, such as region of interest [41], cen-\\ntral saliency [19], and global gray values [42]. Xu et\\nal. [42] proposed Stylized aEsthEtic (SEE) QR codes, pi-\\noneering style-transfer-based techniques for aesthetic QRcodes but encountered visual artifacts from pixel cluster-\\ning. ArtCoder [39] reduced these artifacts by optimizing\\nstyle, content, and code losses jointly, although some arti-\\nfacts remain. Su et al. [38] further improved aesthetics with\\nthe Module-based Deformable Convolutional Mechanism\\n(MDCM). However, these techniques require reference im-\\nages, which leads to a lack of flexibility and variation. 2.2.2 Generative-based Models\\nWith the rise of diffusion-based image manipulation and\\nconditional control techniques, previous works such as QR\\nDiffusion [15], QR Code AI Art [21] and QRBTF [18]\\nhave leveraged generative power of diffusion models to\\ncreate aesthetic QR codes, primarily relying on Control-\\nNet [45] for guidance. However, more fine-grained guid-\\nance that aligns with the inherent mechanisms of QR codes\\nremains unexplored. Another non-open-source method\\nText2QR [40], introduced a three-stage pipeline that first\\ngenerates an unscannable QR code using pre-trained Con-\\ntrolNet, followed by their proposed SELR independent of\\nthe diffusion sampling process to ensure scannability. How-\\never, the diffusion sampling process of Text2QR can not\\nguarantee scannability on its own; our approach aims to fill\\nthis gap by designing a training-free, fine-grained guidance\\nintegrating scannability criteria into the diffusion sampling\\nprocess. 3. Method\\nDiffQRCoder is designed to generate a scannable and at-\\ntractive QR code from a given text prompt pand a target\\nQR code y, which consists of m×mmodules, each of size\\ns×spixels. 3'), Document(metadata={'page': 2, 'source': 'qrcode_diffusion.pdf'}, page_content='[46], Qin et al. [27], and Zavadski et al. [45] proposed\\nadaptation strategies that allow users to fine-tune only the\\nextra output layer instead of the entire model. These advancements have significantly impacted fields\\nincluding image editing [4, 6, 10, 11, 22, 23, 25, 43], text-\\nto-image synthesis [29–31], and commercial product de-\\nvelopement, exemplified by DALL-E2 [26] and Midjour-\\nney [14]. 2.2. Aesthetic QR Codes\\n2.2.1 Non-generative-based Models\\nPrevious works on aesthetic QR codes have focused\\non three main techniques: module deformation, module\\nreshuffling, and style transfers. Module-deformation meth-\\nods, such as Halftone QR codes [3], integrate reference\\nimages by deforming and scaling code modules while\\nmaintaining scanning robustness. Module-reshuffling, in-\\ntroduced by Qart [5], rearranges code modules using\\nGaussian-Jordan elimination to align pixel distributions\\nwith reference images to ensure decoding accuracy. Im-\\nage processing techniques have also been developed to en-\\nhance visual quality, such as region of interest [41], cen-\\ntral saliency [19], and global gray values [42]. Xu et\\nal. [42] proposed Stylized aEsthEtic (SEE) QR codes, pi-\\noneering style-transfer-based techniques for aesthetic QRcodes but encountered visual artifacts from pixel cluster-\\ning. ArtCoder [39] reduced these artifacts by optimizing\\nstyle, content, and code losses jointly, although some arti-\\nfacts remain. Su et al. [38] further improved aesthetics with\\nthe Module-based Deformable Convolutional Mechanism\\n(MDCM). However, these techniques require reference im-\\nages, which leads to a lack of flexibility and variation. 2.2.2 Generative-based Models\\nWith the rise of diffusion-based image manipulation and\\nconditional control techniques, previous works such as QR\\nDiffusion [15], QR Code AI Art [21] and QRBTF [18]\\nhave leveraged generative power of diffusion models to\\ncreate aesthetic QR codes, primarily relying on Control-\\nNet [45] for guidance. However, more fine-grained guid-\\nance that aligns with the inherent mechanisms of QR codes\\nremains unexplored. Another non-open-source method\\nText2QR [40], introduced a three-stage pipeline that first\\ngenerates an unscannable QR code using pre-trained Con-\\ntrolNet, followed by their proposed SELR independent of\\nthe diffusion sampling process to ensure scannability. How-\\never, the diffusion sampling process of Text2QR can not\\nguarantee scannability on its own; our approach aims to fill\\nthis gap by designing a training-free, fine-grained guidance\\nintegrating scannability criteria into the diffusion sampling\\nprocess. 3. Method\\nDiffQRCoder is designed to generate a scannable and at-\\ntractive QR code from a given text prompt pand a target\\nQR code y, which consists of m×mmodules, each of size\\ns×spixels. 3')]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe research paper provides several methods for embedding images in QR codes. These methods can be categorized into non-generative-based models and generative-based models.\n",
      "\n",
      "Non-generative-based models include:\n",
      "*   **Module deformation:** Integrating reference images by deforming and scaling code modules (e.g., Halftone QR codes).\n",
      "*   **Module reshuffling:** Rearranging code modules to align pixel distributions with reference images (e.g., Qart).\n",
      "*   **Style transfer:** Using image processing techniques to enhance visual quality (e.g., Stylized aEsthEtic (SEE) QR codes, ArtCoder, Module-based Deformable Convolutional Mechanism (MDCM)).\n",
      "\n",
      "Generative-based models include:\n",
      "*   Using diffusion models to create aesthetic QR codes (e.g., QR Diffusion, QR Code AI Art, QRBTF).\n",
      "*   Text2QR: A three-stage pipeline that generates an unscannable QR code using pre-trained ControlNet and then uses SELR to ensure scannability.\n",
      "\n",
      "In summary, embedding images in QR codes can be achieved through deforming QR code modules, reshuffling them, transferring styles from reference images, or using generative models like diffusion models.\n",
      "Final Answer: Embedding images in QR codes can be achieved through various methods, including module deformation, module reshuffling, style transfer, and generative models like diffusion models. These methods aim to integrate reference images or styles into the QR code while maintaining scannability.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "res = agent.run(\"Find ways to embed images in qr code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Embedding images in QR codes can be achieved through various methods, including module deformation, module reshuffling, style transfer, and generative models like diffusion models. These methods aim to integrate reference images or styles into the QR code while maintaining scannability.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Embedding images in QR codes can be achieved through various methods, including module deformation, module reshuffling, style transfer, and generative models like diffusion models. These methods aim to integrate reference images or styles into the QR code while maintaining scannability.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
